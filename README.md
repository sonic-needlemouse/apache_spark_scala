# [Apache Spark+Scala](https://t1.ru/internship/item/otkrytaya-shkola-dlya-inzhenerov-dannykh-data-engineer/). Репозиторий проектов.

![logo-wide](spark-scala-dvanalytics.jpeg)

## Описание

Открытая школа – это практический курс, рассчитанный на 16 часов вебинаров и 32 часа самостоятельной практики, включая финальный проект.

Проект включает в себя разработку ETL-пайплайнов для обработки и анализа больших данных. Используя инструменты Scala и Apache Spark, реализованы решения для обработки данных в рамках Hadoop экосистемы. AirFlow используется для организации и автоматизации рабочих процессов.

## Технологии
- Apache Spark
- Hadoop
- Apache AirFlow
- Scala
- SQL

## Структура

| Номер проекта                | Название проекта                          | Краткое описание                                                                                                     |
|------------------------------|-------------------------------------------|----------------------------------------------------------------------------------------------------------------------|
| [Проект 0](task_0)       | Задание на запуск Hadoop в Docker         | Работа с Hadoop HDFS в Docker, включая создание директорий, управление файлами и настройку контейнеров.              |
| [Проект 1](task_1)       | Задание на MapReduce                      | Решение задачи поиска числа в массиве с использованием MapReduce в HDFS.                                             |
| [Проект 2](task_2)       | Задание по Apache Spark (PySpark)         | Использование PySpark для обработки и агрегации больших данных, включая создание RDD и DataFrame.                    |
| [Проект 3](task_3)       | Задания по Scala и Apache Spark           | Решение задач на Scala с использованием Spark, включая работу с датасетами, DataFrame, агрегирование и ранжирование данных. |
| [Проект 4](task_4)       | Анализ данных популярных песен и артистов | Анализ данных о популярных песнях и артистах с использованием Spark, включая оптимизацию запросов.                   |
| [Проект 5](task_5)       | Работа с данными в Hadoop и PostgreSQL    | ETL-операции в Hadoop и PostgreSQL, включая загрузку данных и создание широкой и отфильтрованных таблиц.             |
| [Проект 6](task_6)       | Автоматизированный Data Pipeline          | Создание DAG в Airflow для автоматизации процесса проверки и подсчета строк в таблице Hadoop, отправка результатов по электронной почте. |