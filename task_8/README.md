# Пайплайн обработки и трансформации данных

## Исходная задача

- **Загрузка данных в Hadoop из различных источников:**
  - Из PostgreSQL.
  - Из CSV файлов (`/var/data`).
  - Добавление колонки timestamp во все таблицы в Hadoop.
- **Создание широкой таблицы в ODS:**
  - С партиционированием по датам на каждый час.
- **Создание витрины данных:**
  - С удельными весами клиентов по категориям счетов (меньше 500, 500-1000 и т.д.).
  - В процентном соотношении от общего числа клиентов.
- **Расчет удельного веса мужчин:**
  - В каждой категории счетов, имеющих счет в иностранном банке.
- **Выгрузка полученной витрины в PostgreSQL:**
  - Создание схемы `student57`, если она не существует.
  - Формат данных: category, weight, mans_weight.
  - Создание не менее трех партиций за любые три часа.

## Обзор скриптов

### 1. `student57_hw8.py`
- **Назначение**: Оркестрация рабочего процесса с использованием Apache Airflow.
- **Функциональность**:
  - Планирование и управление задачами, связанными с обработкой данных.
  - Определение задач для чтения CSV-файлов, создания таблиц в Hive и распределения данных.

### 2. `CombineWideTable.scala`
- **Назначение**: Объединение данных из нескольких таблиц Hive в широкую таблицу.
- **Функциональность**:
  - Чтение данных из таблиц Hive (`card`, `person`, `address`, `account`).
  - Выполнение соединений и добавление новых столбцов (год, месяц, день, час).
  - Запись объединенных данных в таблицу Hive с партиционированием.

### 3. `DownloadCsvFiles.scala`
- **Назначение**: Загрузка и обработка CSV-файлов из HDFS.
- **Функциональность**:
  - Чтение CSV-файлов из HDFS.
  - Добавление столбца с временной меткой и запись данных в таблицу Hive.

### 4. `DistributeDataMart.scala`
- **Назначение**: Трансформация и распределение данных в Hive и PostgreSQL.
- **Функциональность**:
  - Выполнение сложного SQL-запроса для трансформации данных.
  - Запись результата в таблицу Hive и динамически созданную таблицу PostgreSQL.

### 5. `DownloadPGTables.scala`
- **Назначение**: Загрузка таблиц из PostgreSQL и их хранение в Hive.
- **Функциональность**:
  - Подключение к PostgreSQL и загрузка указанных таблиц.
  - Добавление столбца с временной меткой и запись данных в таблицу Hive.

## Требования к среде выполнения

Для запуска Scala-скриптов из этого репозитория требуется следующая конфигурация среды:

- **Airflow**: Airflow версии 2.8.1 или совместимые версии. 
- **Java**: Java 8 (1.8) или совместимые версии.
- **Scala**: Scala версии 2.11.8.
- **Инструмент сборки**: Apache Maven для управления зависимостями и сборки Scala-приложений.
- **Дополнительные библиотеки**: Убедитесь, что включена стандартная библиотека Scala (`scala-library`). Для разработки и тестирования должны быть доступны библиотеки, такие как JUnit, ScalaTest и Specs2.

Перед запуском Scala-скриптов убедитесь, что ваша среда разработки соответствует этим требованиям.
